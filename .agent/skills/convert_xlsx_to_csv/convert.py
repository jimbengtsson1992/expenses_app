import pandas as pd
import sys
import os

def convert_xlsx_to_csv(input_path, output_path):
    try:
        # Read the Excel file without assuming a header, to preserve original structure
        # We need the metadata from the top, but for the dataframe we want the actual data
        # which starts at row 4 (index 3)
        df_new = pd.read_excel(input_path, header=3, engine='openpyxl')
        
        # Function to format dates
        def format_date(x):
            if isinstance(x, pd.Timestamp):
                return x.strftime('%Y-%m-%d')
            return x

        # Apply date formatting
        # Note: map works on Series (columns), applymap on DataFrame. 
        # In newer pandas, map can be used on DataFrame but it's safer to target specific columns if possible,
        # or use applymap for older pandas compatibility if needed. However, since we saw 'df.map' in previous
        # view, we stick to what works or standard pandas.
        # Let's perform date formatting securely on the 'Datum' and 'Bokfört' columns if they exist,
        # or generally on object columns that look like dates. 
        # For simplicity and sticking to previous logic:
        df_new = df_new.map(format_date)
        
        # Helper to clean and normalize dataframe
        def clean_df(df):
             if 'Datum' not in df.columns:
                 return df
             
             # Filter garbage rows
             df = df.dropna(subset=['Datum'])
             df = df[~df['Datum'].astype(str).str.contains('Datum|Summa|Transaktionsexport|Totalt', case=False, na=False)]
             
             # Normalize Datum
             # We want yyyy-MM-dd string for final output, but for deduplication datetime is safer,
             # OR just consistent string. Since we format df_new to string earlier, let's stick to string.
             # df_new['Datum'] is already formatted string.
             # df_old['Datum'] might be anything.
             # Let's try to convert to datetime then back to string to ensure canonical format
             df['Datum'] = pd.to_datetime(df['Datum'], errors='coerce').dt.strftime('%Y-%m-%d')
             df = df.dropna(subset=['Datum']) # Drop rows that failed date parsing
             
             # Normalize Belopp (Amount)
             # Should be 'Belopp' column. Check if it exists.
             if 'Belopp' in df.columns:
                 # Remove spaces, comma to dot if needed (though usually read properly if configured)
                 # CSV usually has decimal points if generated by this script.
                 # But just in case:
                 def clean_amount(x):
                     if isinstance(x, str):
                         # If it has comma as decimal separator?
                         # Our script outputs '.', assuming standard python float str.
                         # But if locale mixed in...
                         return pd.to_numeric(x.replace(',', '.').replace(' ', ''), errors='coerce')
                     return pd.to_numeric(x, errors='coerce')
                 
                 cols_to_fix = ['Belopp', 'Utl. belopp']
                 for col in cols_to_fix:
                     if col in df.columns:
                         df[col] = df[col].apply(clean_amount).astype(float)
             
             return df

        df_new = clean_df(df_new)
        
        # Check if output file exists to merge history
        if os.path.exists(output_path):
            try:
                # Read existing CSV
                # separator is ';'
                # Header is on row 4 usually in the output (lines 0,1,2 are metadata)
                df_old = pd.read_csv(output_path, sep=';', skiprows=3, encoding='utf-8')
                
                df_old = clean_df(df_old)
                
                # Concatenate
                df_final = pd.concat([df_new, df_old])
                
                # Drop duplicates
                df_final = df_final.drop_duplicates()
                
            except Exception as e:
                print(f"Warning: Could not read existing file '{output_path}' for merging: {e}")
                print("Proceeding with new data only.")
                df_final = df_new
        else:
            df_final = df_new

        
        # Sort by Datum descending
        if 'Datum' in df_final.columns:
             df_final = df_final.sort_values(by='Datum', ascending=False)

        # Write to CSV
        # We need to construct the file with the metadata header.
        # We'll use the metadata from the NEW file (the XLSX) since that's the latest export.
        
        
        # Read the raw excel again just to get lines 0-2 (metadata)
        # Or simpler: Just hardcode or read the first few rows separately.
        # Let's read the first 3 rows of the XLSX to get the metadata headers.
        df_meta = pd.read_excel(input_path, header=None, nrows=3, engine='openpyxl')
        
        # Write metadata first
        with open(output_path, 'w', encoding='utf-8') as f:
            # metadata to csv string manually to ensure format
            # pandas to_csv might quote things, we want to match the weird format
            # The previous file seemed to just dump the rows.
            # Let's imitate what the previous script did roughly, but more controlled.
            # The previous script did `df.to_csv(..., header=False)`.
            # If we want to preserve the exact top 3 lines structure from the XLSX:
            
            # Convert metadata df to csv string blocks
            # But wait, the previous script read the WHOLE thing as one dataframe and just dumped it.
            # That meant the column headers were just row 4 of the dataframe.
            
            # Let's do this:
            # 1. Write the 3 metadata rows from df_meta
            for i in range(len(df_meta)):
                # Cleanup line 3 (index 2) to avoid "Totalt övriga händelser"
                # which triggers AmexSection.other in parser and filters out negative purchases (refunds).
                row_vals = df_meta.iloc[i].fillna('').astype(str).tolist()
                
                # If any cell contains "Totalt övriga", blank it out or replace
                cleaned_row = []
                for val in row_vals:
                    if "Totalt övriga" in val:
                        cleaned_row.append("") # Replace with empty
                    else:
                        cleaned_row.append(val)
                
                # join with ';' and write
                line = ';'.join(cleaned_row)
                f.write(line + '\n')
            
            # 2. Write the df_final with headers
            df_final.to_csv(f, sep=';', index=False, encoding='utf-8')

        print(f"Successfully converted '{input_path}' to '{output_path}' (merged {len(df_final)} records)")
        
    except Exception as e:
        print(f"Error converting file: {e}")
        sys.exit(1)


if __name__ == "__main__":
    if len(sys.argv) < 3:
        print("Usage: python3 convert.py <input_xlsx_path> <output_csv_path> [--no-validate]")
        sys.exit(1)
        
    input_file = sys.argv[1]
    output_file = sys.argv[2]
    # Default to True, disable if --no-validate is present
    validate = "--no-validate" not in sys.argv
    
    if not os.path.exists(input_file):
        print(f"Error: Input file '{input_file}' not found.")
        sys.exit(1)
        
    convert_xlsx_to_csv(input_file, output_file)
    
    if validate:
        print("\nValidating output...")
        try:
            df = pd.read_csv(output_file, sep=';', skiprows=3, encoding='utf-8')
            
            # Check for duplicates
            # Consider all columns
            dupes = df[df.duplicated()]
            if not dupes.empty:
                print(f"WARNING: Found {len(dupes)} duplicate rows!")
                print(dupes)
            else:
                print("No duplicate rows found.")
                
            # Check sorting
            if 'Datum' in df.columns:
                # Convert to datetime for comparison
                dates = pd.to_datetime(df['Datum'], errors='coerce')
                # Check if monotonic decreasing
                if dates.is_monotonic_decreasing:
                     print("Sorting: OK (Descending)")
                else:
                     print("WARNING: Data is not strictly sorted descending by Date.")
            
            print("Validation complete.")
            
        except Exception as e:
            print(f"Validation failed: {e}")
